package org.hjug.feedback.vertex.kernelized;

import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;
import org.jgrapht.Graph;
import org.jgrapht.Graphs;
import org.jgrapht.alg.cycle.CycleDetector;
import org.jgrapht.graph.DefaultEdge;
import org.jgrapht.graph.DefaultUndirectedGraph;

/**
 * Multithreaded treewidth computer that implements multiple heuristic algorithms
 * for approximating treewidth of graphs after modulator removal.
 * Generated by Perplexity.ai's Research model from papers by Hans L. Bodlaender et al.
 * https://dl.acm.org/doi/10.1137/S0097539793251219
 * https://dl.acm.org/doi/10.1145/2973749
 *
 */
public class TreewidthComputer<V, E> {

    private final ExecutorService executorService;

    public TreewidthComputer() {
        this.executorService = ForkJoinPool.commonPool();
    }

    public TreewidthComputer(int parallelismLevel) {
        this.executorService = Executors.newWorkStealingPool(parallelismLevel);
    }

    /**
     * Computes eta (Î·): the treewidth of the undirected version of the graph
     * after removing the modulator vertices.
     */
    public int computeEta(Graph<V, E> graph, Set<V> modulator) {
        // Convert to undirected graph and remove modulator
        Graph<V, DefaultEdge> undirectedGraph = convertToUndirectedWithoutModulator(graph, modulator);

        // shortcuts
        if (undirectedGraph.vertexSet().isEmpty() || undirectedGraph.vertexSet().size() == 1) {
            return 0;
        } else if (!hasCycles(graph)) {
            // A graph without cycles will have an eta of 1 for our purposes
            // since a graph that does not have cycles is not of interest
            return 1;
        }

        // Run multiple treewidth approximation algorithms in parallel
        List<Callable<Integer>> algorithms = Arrays.asList(
                () -> minDegreeEliminationTreewidth(undirectedGraph),
                () -> fillInHeuristicTreewidth(undirectedGraph),
                () -> maxCliqueTreewidth(undirectedGraph),
                () -> greedyTriangulationTreewidth(undirectedGraph));

        try {
            List<Future<Integer>> results = executorService.invokeAll(algorithms, 30, TimeUnit.SECONDS);

            return results.parallelStream()
                    .map(this::getFutureValue)
                    .filter(Objects::nonNull)
                    .filter(eta -> eta > 1) // if a graph has a cycle, eta will be more than 1
                    .min(Integer::compareTo)
                    .orElse(undirectedGraph.vertexSet().size() - 1); // Worst case bound

        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return computeFallbackTreewidth(undirectedGraph);
        }
    }

    /**
     * Checks if the graph has cycles
     */
    private boolean hasCycles(Graph<V, E> graph) {
        CycleDetector<V, E> detector = new CycleDetector<>(graph);
        return detector.detectCycles();
    }

    /**
     * Converts directed/undirected graph to undirected and removes modulator vertices
     */
    private Graph<V, DefaultEdge> convertToUndirectedWithoutModulator(Graph<V, E> original, Set<V> modulator) {
        Graph<V, DefaultEdge> undirected = new DefaultUndirectedGraph<>(DefaultEdge.class);

        // Add vertices (except modulator)
        original.vertexSet().stream().filter(v -> !modulator.contains(v)).forEach(undirected::addVertex);

        // Add edges
        original.edgeSet().parallelStream().forEach(edge -> {
            V source = original.getEdgeSource(edge);
            V target = original.getEdgeTarget(edge);

            if (undirected.containsVertex(source)
                    && undirected.containsVertex(target)
                    && !source.equals(target)
                    && !undirected.containsEdge(source, target)) {

                synchronized (undirected) {
                    if (!undirected.containsEdge(source, target)) {
                        undirected.addEdge(source, target);
                    }
                }
            }
        });

        return undirected;
    }

    /**
     * Minimum degree elimination ordering heuristic
     */
    private int minDegreeEliminationTreewidth(Graph<V, DefaultEdge> graph) {
        Set<V> remainingVertices =
                new ConcurrentHashMap<>(graph.vertexSet().stream().collect(Collectors.toMap(v -> v, v -> v))).keySet();

        Map<V, Set<V>> adjacencyMap = new ConcurrentHashMap<>();

        // Initialize adjacency map
        graph.vertexSet().parallelStream().forEach(v -> {
            adjacencyMap.put(v, ConcurrentHashMap.newKeySet());
            adjacencyMap.get(v).addAll(Graphs.neighborSetOf(graph, v));
        });

        int maxBagSize = 0;

        while (!remainingVertices.isEmpty()) {
            // Find vertex with minimum degree
            V minDegreeVertex = remainingVertices.parallelStream()
                    .min(Comparator.comparingInt(v -> (int) adjacencyMap.get(v).stream()
                            .filter(remainingVertices::contains)
                            .count()))
                    .orElse(null);

            if (minDegreeVertex == null) break;

            Set<V> neighbors = adjacencyMap.get(minDegreeVertex).stream()
                    .filter(remainingVertices::contains)
                    .collect(Collectors.toSet());

            maxBagSize = Math.max(maxBagSize, neighbors.size());

            // Make neighbors a clique
            neighbors.parallelStream().forEach(u -> {
                neighbors.parallelStream().filter(v -> !v.equals(u)).forEach(v -> {
                    adjacencyMap.get(u).add(v);
                    adjacencyMap.get(v).add(u);
                });
            });

            remainingVertices.remove(minDegreeVertex);
        }

        return maxBagSize;
    }

    /**
     * Computes an upper bound on treewidth using the minimum fill-in heuristic with parallelization.
     *
     * The minimum fill-in heuristic repeatedly eliminates the vertex that requires
     * the minimum number of edges to be added to make its neighborhood a clique.
     * This implementation uses parallel streams and concurrent data structures for better performance.
     *
     * @return an upper bound on the treewidth of the graph
     */
    public int fillInHeuristicTreewidth(Graph<V, DefaultEdge> graph) {
        if (graph.vertexSet().isEmpty()) {
            return 0;
        }

        // Create a working copy of the graph using concurrent data structures
        ConcurrentHashMap<V, Set<V>> adjacencyMap = new ConcurrentHashMap<>();

        // Initialize adjacency map in parallel
        graph.vertexSet().parallelStream().forEach(vertex -> {
            Set<V> neighbors = ConcurrentHashMap.newKeySet();

            // Add in-neighbors
            graph.incomingEdgesOf(vertex).parallelStream()
                    .map(graph::getEdgeSource)
                    .filter(neighbor -> !neighbor.equals(vertex))
                    .forEach(neighbors::add);

            // Add out-neighbors
            graph.outgoingEdgesOf(vertex).parallelStream()
                    .map(graph::getEdgeTarget)
                    .filter(neighbor -> !neighbor.equals(vertex))
                    .forEach(neighbors::add);

            adjacencyMap.put(vertex, neighbors);
        });

        AtomicInteger maxCliqueSize = new AtomicInteger(0);
        ConcurrentHashMap<V, Boolean> remainingVertices = new ConcurrentHashMap<>();

        // Initialize remaining vertices
        graph.vertexSet().parallelStream().forEach(vertex -> remainingVertices.put(vertex, true));

        // Custom ForkJoinPool for better control over parallelization
        ForkJoinPool customThreadPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());

        try {
            // Main elimination loop
            while (!remainingVertices.isEmpty()) {

                // Find vertex with minimum fill-in in parallel
                Optional<Map.Entry<V, Integer>> bestVertexEntry = customThreadPool
                        .submit(() -> remainingVertices.keySet().parallelStream()
                                .collect(Collectors.toConcurrentMap(
                                        vertex -> vertex,
                                        vertex -> calculateFillInParallel(vertex, adjacencyMap, remainingVertices)))
                                .entrySet()
                                .parallelStream()
                                .min(Map.Entry.comparingByValue()))
                        .get();

                if (!bestVertexEntry.isPresent()) {
                    // Fallback: choose any remaining vertex
                    V fallbackVertex = remainingVertices.keys().nextElement();
                    eliminateVertexParallel(fallbackVertex, adjacencyMap, remainingVertices, maxCliqueSize);
                } else {
                    V bestVertex = bestVertexEntry.get().getKey();
                    eliminateVertexParallel(bestVertex, adjacencyMap, remainingVertices, maxCliqueSize);
                }
            }
        } catch (InterruptedException | ExecutionException e) {
            Thread.currentThread().interrupt();
            throw new RuntimeException("Parallel computation interrupted", e);
        } finally {
            customThreadPool.shutdown();
        }

        return maxCliqueSize.get();
    }

    /**
     * Alternative implementation using CompletableFuture for more complex parallel operations.
     * TODO: Explore later
     */
    public CompletableFuture<Integer> fillInHeuristicTreewidthAsync(Graph<V, DefaultEdge> graph) {
        return CompletableFuture.supplyAsync(() -> {
            if (graph.vertexSet().isEmpty()) {
                return 0;
            }

            // Initialize concurrent data structures
            ConcurrentHashMap<V, Set<V>> adjacencyMap = new ConcurrentHashMap<>();
            ConcurrentHashMap<V, Boolean> remainingVertices = new ConcurrentHashMap<>();
            AtomicInteger maxCliqueSize = new AtomicInteger(0);

            // Parallel initialization
            List<CompletableFuture<Void>> initFutures = graph.vertexSet().stream()
                    .map(vertex -> CompletableFuture.runAsync(() -> {
                        Set<V> neighbors = ConcurrentHashMap.newKeySet();

                        graph.incomingEdgesOf(vertex).parallelStream()
                                .map(graph::getEdgeSource)
                                .filter(neighbor -> !neighbor.equals(vertex))
                                .forEach(neighbors::add);

                        graph.outgoingEdgesOf(vertex).parallelStream()
                                .map(graph::getEdgeTarget)
                                .filter(neighbor -> !neighbor.equals(vertex))
                                .forEach(neighbors::add);

                        adjacencyMap.put(vertex, neighbors);
                        remainingVertices.put(vertex, true);
                    }))
                    .collect(Collectors.toList());

            // Wait for initialization to complete
            CompletableFuture.allOf(initFutures.toArray(new CompletableFuture[0]))
                    .join();

            // Main elimination loop
            while (!remainingVertices.isEmpty()) {
                CompletableFuture<V> bestVertexFuture =
                        CompletableFuture.supplyAsync(() -> remainingVertices.keySet().parallelStream()
                                .min(Comparator.comparingInt(
                                        vertex -> calculateFillInParallel(vertex, adjacencyMap, remainingVertices)))
                                .orElse(remainingVertices.keys().nextElement()));

                V bestVertex = bestVertexFuture.join();
                eliminateVertexParallel(bestVertex, adjacencyMap, remainingVertices, maxCliqueSize);
            }

            return maxCliqueSize.get();
        });
    }

    /**
     * Eliminates a vertex and updates the graph structure in parallel.
     *
     * @param vertex the vertex to eliminate
     * @param adjacencyMap the current adjacency representation
     * @param remainingVertices vertices that haven't been eliminated yet
     * @param maxCliqueSize atomic reference to track maximum clique size
     */
    private void eliminateVertexParallel(
            V vertex,
            ConcurrentHashMap<V, Set<V>> adjacencyMap,
            ConcurrentHashMap<V, Boolean> remainingVertices,
            AtomicInteger maxCliqueSize) {
        Set<V> neighborhood = getNeighborhoodParallel(vertex, adjacencyMap, remainingVertices);

        // Update maximum clique size atomically
        maxCliqueSize.updateAndGet(current -> Math.max(current, neighborhood.size()));

        // Make the neighborhood a clique in parallel
        fillInNeighborhoodParallel(neighborhood, adjacencyMap);

        // Remove the eliminated vertex
        remainingVertices.remove(vertex);
        adjacencyMap.remove(vertex);

        // Remove vertex from all neighbor sets in parallel
        adjacencyMap.values().parallelStream().forEach(neighbors -> neighbors.remove(vertex));
    }

    /**
     * Gets the neighborhood of a vertex using parallel processing.
     *
     * @param vertex the vertex whose neighborhood to find
     * @param adjacencyMap the current adjacency representation
     * @param remainingVertices vertices that haven't been eliminated yet
     * @return the set of neighboring vertices that are still remaining
     */
    private Set<V> getNeighborhoodParallel(
            V vertex, ConcurrentHashMap<V, Set<V>> adjacencyMap, ConcurrentHashMap<V, Boolean> remainingVertices) {
        Set<V> allNeighbors = adjacencyMap.getOrDefault(vertex, ConcurrentHashMap.newKeySet());

        // Filter to only remaining vertices in parallel
        return allNeighbors.parallelStream()
                .filter(remainingVertices::containsKey)
                .collect(Collectors.toConcurrentMap(
                        neighbor -> neighbor,
                        neighbor -> true,
                        (existing, replacement) -> true,
                        ConcurrentHashMap::new))
                .keySet();
    }

    /**
     * Adds edges to make the given set of vertices form a clique using parallel processing.
     *
     * @param vertices the vertices that should form a clique
     * @param adjacencyMap the adjacency map to modify
     */
    private void fillInNeighborhoodParallel(Set<V> vertices, ConcurrentHashMap<V, Set<V>> adjacencyMap) {
        List<V> vertexList = new ArrayList<>(vertices);

        // Add all missing edges to make it a clique in parallel
        vertexList.parallelStream().forEach(v1 -> {
            int index1 = vertexList.indexOf(v1);
            vertexList.stream().skip(index1 + 1).parallel().forEach(v2 -> {
                // Add edges in both directions atomically
                adjacencyMap
                        .computeIfAbsent(v1, k -> ConcurrentHashMap.newKeySet())
                        .add(v2);
                adjacencyMap
                        .computeIfAbsent(v2, k -> ConcurrentHashMap.newKeySet())
                        .add(v1);
            });
        });
    }

    /**
     * Calculates the fill-in value for a vertex using parallel processing.
     *
     * @param vertex the vertex to calculate fill-in for
     * @param adjacencyMap the current adjacency representation
     * @param remainingVertices vertices that haven't been eliminated yet
     * @return the number of edges needed to make the neighborhood a clique
     */
    private int calculateFillInParallel(
            V vertex, ConcurrentHashMap<V, Set<V>> adjacencyMap, ConcurrentHashMap<V, Boolean> remainingVertices) {
        Set<V> neighborhood = getNeighborhoodParallel(vertex, adjacencyMap, remainingVertices);

        if (neighborhood.size() <= 1) {
            return 0; // Already a clique (or empty)
        }

        List<V> neighborList = new ArrayList<>(neighborhood);

        // Count missing edges in parallel
        return neighborList.parallelStream()
                .mapToInt(v1 -> {
                    int index1 = neighborList.indexOf(v1);
                    return (int) neighborList.stream()
                            .skip(index1 + 1)
                            .parallel()
                            .filter(v2 -> !hasEdgeParallel(v1, v2, adjacencyMap))
                            .count();
                })
                .sum();
    }

    /**
     * Checks if an edge exists between two vertices.
     *
     * @param v1 first vertex
     * @param v2 second vertex
     * @param adjacencyMap the current adjacency representation
     * @return true if an edge exists in either direction
     */
    private boolean hasEdgeParallel(V v1, V v2, ConcurrentHashMap<V, Set<V>> adjacencyMap) {
        Set<V> neighborsV1 = adjacencyMap.get(v1);
        Set<V> neighborsV2 = adjacencyMap.get(v2);

        return (neighborsV1 != null && neighborsV1.contains(v2)) || (neighborsV2 != null && neighborsV2.contains(v1));
    }

    /**
     * Maximum clique based treewidth lower bound
     */
    private int maxCliqueTreewidth(Graph<V, DefaultEdge> graph) {
        if (graph.vertexSet().size() <= 50) {
            return findMaxCliqueBronKerbosch(graph) - 1;
        } else {
            return findMaxCliqueGreedy(graph) - 1;
        }
    }

    /**
     * Greedy triangulation heuristic
     */
    private int greedyTriangulationTreewidth(Graph<V, DefaultEdge> graph) {
        Map<V, Set<V>> adjacencyMap = new ConcurrentHashMap<>();

        // Initialize adjacency map
        graph.vertexSet().parallelStream().forEach(v -> {
            adjacencyMap.put(v, ConcurrentHashMap.newKeySet());
            adjacencyMap.get(v).addAll(Graphs.neighborSetOf(graph, v));
        });

        int maxBagSize = 0;
        Queue<V> eliminationOrder = new ConcurrentLinkedQueue<>(graph.vertexSet());

        while (!eliminationOrder.isEmpty()) {
            V vertex = eliminationOrder.poll();
            if (vertex == null) break;

            Set<V> neighbors = adjacencyMap.get(vertex);
            maxBagSize = Math.max(maxBagSize, neighbors.size());

            // Triangulate neighborhood
            triangulateNeighborhood(neighbors, adjacencyMap);
        }

        return maxBagSize;
    }

    private void triangulateNeighborhood(Set<V> neighbors, Map<V, Set<V>> adjacencyMap) {
        List<V> neighborList = new ArrayList<>(neighbors);
        neighborList.parallelStream().forEach(u -> {
            neighborList.parallelStream()
                    .filter(v -> !v.equals(u) && !adjacencyMap.get(u).contains(v))
                    .forEach(v -> {
                        adjacencyMap.get(u).add(v);
                        adjacencyMap.get(v).add(u);
                    });
        });
    }

    // original implementation
    private int calculateFillIn(Set<V> neighbors, Map<V, Set<V>> adjacencyMap) {
        AtomicInteger fillIn = new AtomicInteger(0);

        neighbors.parallelStream().forEach(u -> {
            neighbors.parallelStream()
                    .filter(v -> !v.equals(u) && !adjacencyMap.get(u).contains(v))
                    .forEach(v -> fillIn.incrementAndGet());
        });

        return fillIn.get() / 2; // Each edge counted twice
    }

    private int findMaxCliqueBronKerbosch(Graph<V, DefaultEdge> graph) {
        Set<V> R = new HashSet<>();
        Set<V> P = new HashSet<>(graph.vertexSet());
        Set<V> X = new HashSet<>();
        AtomicInteger maxCliqueSize = new AtomicInteger(0);

        bronKerbosch(graph, R, P, X, maxCliqueSize);
        return maxCliqueSize.get();
    }

    private void bronKerbosch(Graph<V, DefaultEdge> graph, Set<V> R, Set<V> P, Set<V> X, AtomicInteger maxSize) {
        if (P.isEmpty() && X.isEmpty()) {
            maxSize.set(Math.max(maxSize.get(), R.size()));
            return;
        }

        for (V vertex : new HashSet<>(P)) {
            Set<V> neighbors = Graphs.neighborSetOf(graph, vertex);

            Set<V> newR = new HashSet<>(R);
            newR.add(vertex);

            Set<V> newP = new HashSet<>(P);
            newP.retainAll(neighbors);

            Set<V> newX = new HashSet<>(X);
            newX.retainAll(neighbors);

            bronKerbosch(graph, newR, newP, newX, maxSize);

            P.remove(vertex);
            X.add(vertex);
        }
    }

    private int findMaxCliqueGreedy(Graph<V, DefaultEdge> graph) {
        return graph.vertexSet().parallelStream()
                .mapToInt(v -> Graphs.neighborSetOf(graph, v).size() + 1)
                .max()
                .orElse(1);
    }

    private int computeFallbackTreewidth(Graph<V, DefaultEdge> graph) {
        // Simple fallback: maximum degree
        return graph.vertexSet().parallelStream()
                .mapToInt(v -> graph.degreeOf(v))
                .max()
                .orElse(0);
    }

    private Integer getFutureValue(Future<Integer> future) {
        try {
            return future.get();
        } catch (Exception e) {
            return null;
        }
    }

    public void shutdown() {
        if (executorService != null && !executorService.isShutdown()) {
            executorService.shutdown();
        }
    }
}
